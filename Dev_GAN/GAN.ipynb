{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numpy and matplotlib\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dataset\n",
    "import keras.datasets as ds\n",
    "\n",
    "# Unconditional GAN\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, Dropout, BatchNormalization, UpSampling2D\n",
    "\n",
    "# Conditional GAN\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Concatenate\n",
    "\n",
    "# Visualization tools\n",
    "from IPython.display import clear_output, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load selected dataset\n",
    "def load_dataset(dataset):\n",
    "\n",
    "    if dataset == 'MNIST':\n",
    "        (trainX, trainy), (_, _) = ds.mnist.load_data()\n",
    "\n",
    "    if dataset == 'Fashion-MNIST':\n",
    "        (trainX, trainy), (_, _) = ds.fanshion_mnist.load_data()\n",
    "\n",
    "    # Exapnd to 3D adding one channel\n",
    "    X = np.expand_dims(trainX, axis=-1)\n",
    "\n",
    "    # Convert from int to float and rescale from [0, 255] to [-1, 1]\n",
    "    X = X.astype('float32')\n",
    "    X = (X - (255 / 2)) / (255 / 2)\n",
    "    return [X, trainy]\n",
    "\n",
    "\n",
    "\n",
    "# Build Discriminator\n",
    "def build_discriminator(input_shape):\n",
    "\n",
    "    # Initialize the NN\n",
    "    model = Sequential()\n",
    "\n",
    "    # First convolutional layer\n",
    "    model.add(Conv2D(128, 3, strides=2, padding='same', input_shape=input_shape))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Second convolutional layer\n",
    "    model.add(Conv2D(256, 3, strides=2, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # Flattening and output layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Build Generator with default latent_space=100\n",
    "def build_generator(latent_dim=100):\n",
    "\n",
    "    # Initialize the NN\n",
    "    model = Sequential()\n",
    "\n",
    "    # Fully connected layer\n",
    "    model.add(Dense(7 * 7 * 128, input_dim=latent_dim))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "    model.add(Reshape((7, 7, 128)))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    # First upsampling layer 14x14\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Second upsampling layer 28x28\n",
    "    model.add(UpSampling2D())\n",
    "    model.add(Conv2D(128, 3, padding='same'))\n",
    "    model.add(BatchNormalization(momentum=0.9))\n",
    "    model.add(LeakyReLU(alpha=0.2))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Conv2D(1, 7, activation='tanh', padding='same'))\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "# Build the GAN framework\n",
    "def build_gan(input_shape, latent_dim):\n",
    "\n",
    "    opt = Adam(lr=0.0002, beta_1=0.5)\n",
    "\n",
    "    # Build Discriminator and Generator\n",
    "    D = build_discriminator(input_shape=input_shape)\n",
    "    G = build_generator(latent_dim=latent_dim)\n",
    "    G.compile(loss='binary_crossentropy', optimizer=opt)\n",
    "\n",
    "    # Freeze discriminator weights during generator training\n",
    "    D.trainable = False\n",
    "\n",
    "    # Connect generator and discriminator\n",
    "    GAN = Sequential()\n",
    "    GAN.add(G)\n",
    "    GAN.add(D)\n",
    "    GAN.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "    return GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_real(dataset, batch_size):\n",
    "    X = dataset[np.random.randint(0, dataset.shape[0], size=batch_size), :, :, :]\n",
    "    y = np.ones((batch_size, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def gen_fake(G, latent_dim, batch_size):\n",
    "    z = np.random.randn(latent_dim * batch_size)\n",
    "    z = z.reshape(batch_size, latent_dim)\n",
    "    X = G.predict(z)\n",
    "    y = np.zeros((batch_size, 1))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# Train the GAN\n",
    "def train(D, G, GAN, dataset, latent_dim=100, epochs=20, batch_size=128):\n",
    "    \n",
    "    batch_per_epoch = int(dataset.shape[0] / batch_size)\n",
    "    half_batch = int(batch_size / 2)\n",
    "    \n",
    "    D_loss = []\n",
    "    D_acc = []\n",
    "    G_loss = []\n",
    "    G_acc = []\n",
    "    \n",
    "\n",
    "    # Loop over epochs\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        eD_loss = []\n",
    "        eD_acc = []\n",
    "        eG_loss = []\n",
    "        eG_acc = []\n",
    "        \n",
    "        for mbatch in range(batch_per_epoch):\n",
    "\n",
    "            # Random select half_batch real samples\n",
    "            realX, realY = gen_real(dataset, half_batch)\n",
    "            \n",
    "            # Random generate half_batch fake samples\n",
    "            fakeX, fakeY = gen_fake(G, latent_dim, half_batch)\n",
    "\n",
    "            # Stacks all samples together and train the discriminator\n",
    "            X, y = np.vstack((realX, fakeX)), np.vstack((realY, fakeY))\n",
    "            D_stats = D.train_on_batch(X, y)\n",
    "            \n",
    "            # Generate random noise and labels to train the Generator\n",
    "            Z_gan = np.random.randn(latent_dim * batch_size).reshape(batch_size, latent_dim)\n",
    "            y_gan = np.ones((batch_size, 1))\n",
    "            G_stats = GAN.train_on_batch(Z_gan, y_gan)\n",
    "            \n",
    "            # Save batch parameters\n",
    "            eD_loss.append(D_stats[0])\n",
    "            eD_acc.append(D_stats[1])\n",
    "            eG_loss.append(G_stats[0])\n",
    "            eG_acc.append(G_stats[1])\n",
    "        \n",
    "        # Save all\n",
    "        D_loss.append(eD_loss)\n",
    "        D_acc.append(eD_acc)\n",
    "        G_loss.append(eG_loss)\n",
    "        G_acc.append(eG_acc)\n",
    "        \n",
    "        # Print epoch mean value\n",
    "        print('Epoch-%d: dl=%.3f gl=%.3f da=%.3f ga=%.3f' %(epoch, np.mean(eD_loss), np.mean(eG_loss), np.mean(eD_acc), np.mean(eG_acc)))\n",
    "        \n",
    "    return D_loss, D_acc, G_loss, G_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "trainX, trainy = load_dataset('MNIST')\n",
    "\n",
    "# Define latent space\n",
    "latent_space = 100\n",
    "in_shape = (trainX[0].shape[0], trainX[0].shape[1], 1)\n",
    "\n",
    "# Build Generator and Discriminator\n",
    "D = build_discriminator(input_shape=in_shape)\n",
    "G = build_generator(latent_dim=latent_space)\n",
    "\n",
    "# Create DCGAN framework\n",
    "GAN = build_gan(in_shape, latent_space)\n",
    "\n",
    "D.summary()\n",
    "# Train DCGAN\n",
    "#D_l, D_a, G_l, G_a = train(D, G, GAN, trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train DCGAN\n",
    "D_l, D_a, G_l, G_a = train(D, G, GAN, trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    tmp_z = np.random.randn(latent_space).reshape(1,latent_space)\n",
    "\n",
    "    gen = G.predict(tmp_z)\n",
    "    #print(gen[0].shape)\n",
    "    plt.imshow(gen[0, :, :, 0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
